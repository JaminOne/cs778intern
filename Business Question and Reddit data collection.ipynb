{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Business Question and Reddit data collection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1mokx31UI8KimCZUSGKyfDG3H8PltjRAM","authorship_tag":"ABX9TyMlmnd/XaEC3SRaIbMS1hTr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0ijUHxKS-wtt"},"source":["# Business Problem\n","The COVID-19 pandemic took our world by storm, and there is no doubt that covid related topic becomes the most popular one in the social media. Stay at home order makes more people to express opinions at social media like Facebook, Twitter and Reddit. \n","\n","In this business problem, I will use Reddit API to get the top500 posts and their comments at COVID-19 related subreddit. Topic modeling, sentiment analysis and prediction will be used to build a machine learning pipeline by investigate public opinion on all kinds of text content on Reddit and helping decision makers to make better policies.\n","\n","### Objective\n","*   Successfully build a machine learning pipeline to collect data, analyze  and predict the sentiment.  \n","*   Help decision maker understand importance of using public opinion \n","*   Help decision maker to find possible issue surrouding the COVID\n","\n","\n"," "]},{"cell_type":"code","metadata":{"id":"w2otx89s3Pfe","executionInfo":{"status":"ok","timestamp":1600654057270,"user_tz":-720,"elapsed":5926,"user":{"displayName":"Jamin Wan","photoUrl":"","userId":"00288590089766237280"}},"outputId":"a08ce6ef-0846-49e0-b74f-0d343dc800bb","colab":{"base_uri":"https://localhost:8080/","height":339}},"source":["pip install praw"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting praw\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/15/4bcc44271afce0316c73cd2ed35f951f1363a07d4d5d5440ae5eb2baad78/praw-7.1.0-py3-none-any.whl (152kB)\n","\r\u001b[K     |██▏                             | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 2.9MB/s \n","\u001b[?25hCollecting update-checker>=0.17\n","  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n","Collecting websocket-client>=0.54.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 8.8MB/s \n","\u001b[?25hCollecting prawcore<2.0,>=1.3.0\n","  Downloading https://files.pythonhosted.org/packages/1d/40/b741437ce4c7b64f928513817b29c0a615efb66ab5e5e01f66fe92d2d95b/prawcore-1.5.0-py3-none-any.whl\n","Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.17->praw) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2020.6.20)\n","Installing collected packages: update-checker, websocket-client, prawcore, praw\n","Successfully installed praw-7.1.0 prawcore-1.5.0 update-checker-0.18.0 websocket-client-0.57.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vc-qVXbr2-8a"},"source":["import datetime\n","import praw\n","import pandas as pd\n","#from keys import client_id, client_secret"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2ytU0zpbZB5"},"source":["client_id = '**'\n","client_secret = '**'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0EB7Pc64LHL"},"source":["## Collecting the posts for our topic\n","Initializing a Reddit Instance"]},{"cell_type":"code","metadata":{"id":"NL4GaxHC3H9P"},"source":["reddit = praw.Reddit( client_id=client_id,\n","            client_secret=client_secret,\n","            user_agent='android:my_app:v1 (by /u/HardPlayer23)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnB2Qv275VLf"},"source":["covid = reddit.subreddit('CoronavirusCanada')\n","\n","#Gathering the top 500 posts, with their title, url, body, upvotes, timestamp, and an index that serves as a key between the\n","#posts and the comments we collect later\n","posts = []\n","for index, post in enumerate(covid.top(limit=20)):\n","    posts.append([post.title, \"https://www.reddit.com\" + post.permalink, post.selftext, post.score, post.created_utc, index])\n","\n","#Converting into DataFrame\n","posts = pd.DataFrame(posts, columns=['Title', 'URL', 'Body', 'Upvotes', 'Time', 'Key'])\n","#Changing from utc time to standard timestamp\n","posts.Time = posts.Time.apply(lambda x: pd.to_datetime(datetime.datetime.fromtimestamp(x)))\n","\n","#The first post is a sticky, so we can drop it\n","posts = posts.iloc[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luwGurkh6H43","executionInfo":{"status":"ok","timestamp":1600663314591,"user_tz":-720,"elapsed":853,"user":{"displayName":"Jamin Wan","photoUrl":"","userId":"00288590089766237280"}},"outputId":"0a43a6ff-1f77-4e77-8816-d83e7456d23c","colab":{"base_uri":"https://localhost:8080/","height":450}},"source":["posts.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>URL</th>\n","      <th>Body</th>\n","      <th>Upvotes</th>\n","      <th>Time</th>\n","      <th>Key</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>British public: “We love the NHS!” *elects Con...</td>\n","      <td>https://www.reddit.com/r/CoronavirusUK/comment...</td>\n","      <td></td>\n","      <td>3817</td>\n","      <td>2020-04-18 10:24:05</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Richard Branson is worth $4 billion dollars an...</td>\n","      <td>https://www.reddit.com/r/CoronavirusUK/comment...</td>\n","      <td></td>\n","      <td>1999</td>\n","      <td>2020-04-01 10:26:15</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Just about the kindest thing to happen in the ...</td>\n","      <td>https://www.reddit.com/r/CoronavirusUK/comment...</td>\n","      <td></td>\n","      <td>1639</td>\n","      <td>2020-03-29 13:54:37</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Over Bristol tonight</td>\n","      <td>https://www.reddit.com/r/CoronavirusUK/comment...</td>\n","      <td></td>\n","      <td>1496</td>\n","      <td>2020-06-02 17:33:16</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Wetherspoons: Just Say No</td>\n","      <td>https://www.reddit.com/r/CoronavirusUK/comment...</td>\n","      <td></td>\n","      <td>1463</td>\n","      <td>2020-03-25 09:32:06</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Title  ... Key\n","1  British public: “We love the NHS!” *elects Con...  ...   1\n","2  Richard Branson is worth $4 billion dollars an...  ...   2\n","3  Just about the kindest thing to happen in the ...  ...   3\n","4                               Over Bristol tonight  ...   4\n","5                          Wetherspoons: Just Say No  ...   5\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"4TZHSn8e6ObO","executionInfo":{"status":"ok","timestamp":1600660286030,"user_tz":-720,"elapsed":953,"user":{"displayName":"Jamin Wan","photoUrl":"","userId":"00288590089766237280"}},"outputId":"096bab4e-7bcc-4a31-daf3-419934a271e0","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["posts.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(19, 6)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"LlsUSlvr6sW3"},"source":["\n","**Collecting the comments for each of our posts**\n","\n","We want to get all the comments for the posts we collected"]},{"cell_type":"code","metadata":{"id":"PcTSS0Z-6oTz"},"source":["def collect_replies(key, url):\n","    ''' \n","    params pandas series row: each row of the dataframe we built above in the form of a panda series\n","    Returns a pandas DataFrame, where each row represents an individual comment\n","    '''\n","    submission = reddit.submission(url=url)\n","    submission.comments.replace_more(limit=None)\n","    comment_queue = submission.comments[:] \n","\n","    table = {'Reply':[], 'Upvote':[], 'Time':[], 'Key':[]}\n","\n","    while comment_queue:\n","        comment = comment_queue.pop(0)\n","        table['Reply'].append(comment.body)\n","        table['Time'].append(comment.created_utc)\n","        table['Upvote'].append(comment.score)\n","        table['Key'].append(key)\n","        comment_queue.extend(comment.replies)\n","    \n","    return pd.DataFrame.from_dict(table)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dPNFsd3R7Irw"},"source":["#Let us first generate a list of tupules that contains the key and url for each row - the first value of the tupule is key,\n","#and the second value is url\n","keys = posts.Key.tolist()\n","urls = posts.URL.tolist()\n","tupules = list(zip(keys, urls))\n","\n","#Now we generate our comments dataframe using list comprehensions!\n","comments = pd.concat([collect_replies(x[0], x[1]) for x in tupules])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zebmEMRfSiu"},"source":["#Again, converting the timestamp from utc to a standard format\n","comments.Time = comments.Time.apply(lambda x: pd.to_datetime(datetime.datetime.fromtimestamp(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCNzHQP17NbK","executionInfo":{"status":"ok","timestamp":1600663670600,"user_tz":-720,"elapsed":896,"user":{"displayName":"Jamin Wan","photoUrl":"","userId":"00288590089766237280"}},"outputId":"a42b4217-e767-4c87-b9af-5d7e507dc704","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["comments.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Reply</th>\n","      <th>Upvote</th>\n","      <th>Time</th>\n","      <th>Key</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This should be WAY upvoted. I’ve been waiting ...</td>\n","      <td>18</td>\n","      <td>2020-05-13 04:20:47</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Good to know, once this comes out to the masse...</td>\n","      <td>14</td>\n","      <td>2020-05-13 05:29:30</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>If you're in BC, the BCCDC has a survey where ...</td>\n","      <td>9</td>\n","      <td>2020-05-13 05:40:04</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Excellent. This can be great for determining i...</td>\n","      <td>6</td>\n","      <td>2020-05-13 12:18:57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[deleted]</td>\n","      <td>6</td>\n","      <td>2020-05-13 19:23:21</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Reply  ...  Key\n","0  This should be WAY upvoted. I’ve been waiting ...  ...    1\n","1  Good to know, once this comes out to the masse...  ...    1\n","2  If you're in BC, the BCCDC has a survey where ...  ...    1\n","3  Excellent. This can be great for determining i...  ...    1\n","4                                          [deleted]  ...    1\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"L915MCROAso1","executionInfo":{"status":"ok","timestamp":1600663674165,"user_tz":-720,"elapsed":826,"user":{"displayName":"Jamin Wan","photoUrl":"","userId":"00288590089766237280"}},"outputId":"ec886291-f107-403e-8ad5-6ab35525c86c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["comments.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(588, 4)"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"9XslV7xGA4eH"},"source":["comments.to_csv('Comments_canadatop20.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzbXJSPwFXcE"},"source":["posts.to_csv('Posts_canadatop20.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehAVPaXwFZgo"},"source":["!cp Comments_.csv \"drive/My Drive/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PdbrSPzVfCP"},"source":[""],"execution_count":null,"outputs":[]}]}